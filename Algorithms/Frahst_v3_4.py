# -*- coding: utf-8 -*-"""Created on Sat Mar 05 23:19:11 2011THIS IS THE VERSION TO RUN ON MAC, NOT WINDOWS@author: musselle"""from numpy import eye, zeros, dot, sqrt, log10, trace, arccos, nan, arangeimport numpy as npfrom numpy.random import randfrom numpy.linalg import qr, eig, norm, solvefrom matplotlib.pyplot import plot, figure, title, stepfrom artSigs import genCosSignals_no_rand , genCosSignalsimport scipy.io as siofrom utils import analysis, QRsolveA, pltSummary2from PedrosFrahst import frahst_pedro_originalfrom Frahst_v3_1 import FRAHST_V3_1from Frahst_v3_3 import FRAHST_V3_3from load_syn_ping_data import load_n_storedef FRAHST_V3_4(data, r=1, alpha=0.96, e_low=0.96, e_high=0.98, fix_init_Q = 0, holdOffTime=0,                 evalMetrics = 'F', static_r = 0, r_upper_bound = None, L = 5, ignoreUp2 = 0):    """        Fast Rank Adaptive Householder Subspace Tracking Algorithm (FRAHST)          VErsion 3.4 - input data z is time lagged series up to length l.                 - Algorithm is essentially same as 3.3, just adds pre processing to data vector                - input Vector z_t is now of length (N times L) where L is window length                - Q is increased accordingly                     Version 3.3 - Add decay of S and in the event of vanishing inputs                 - Make sure rank of S does not drop (and work out what that means!) - stops S going singular            Version 3.2 -  Added ability to fix r to a static value., and also give it an upper bound.                   If undefined, defaults to num of data streams.             Version 3.1 - Combines good bits of Pedros version, with my correction of the bugs        Changed how the algorithm deals with sci. only difference, but somehow has a bigish     effect on the output.        """           # Initialise variables and data structures     #########################################    # Derived Variables     # Length of z or numStreams is now N x L     numStreams = data.shape[1] * L    timeSteps = data.shape[0]        if r_upper_bound == None :        r_upper_bound = numStreams        #for energy test    lastChangeAt = 1        sumYSq = 0.    sumXSq = 0.        # Data Stores    res = {'hidden' :  zeros((timeSteps, numStreams)) * nan,  # Array for hidden Variables           'E_t' : zeros([timeSteps, 1]),                     # total energy of data            'E_dash_t' : zeros([timeSteps, 1]),                # hidden var energy           'e_ratio' : zeros([timeSteps, 1]),              # Energy ratio            'RSRE' : zeros([timeSteps, 1]),           # Relative squared Reconstruction error            'recon' : zeros([timeSteps, numStreams]),  # reconstructed data           'r_hist' : zeros([timeSteps, 1]), # history of r values            'anomalies' : []}                  # Initialisations     # Q_0    if fix_init_Q != 0:  # fix inital Q as identity         q_0 = eye(numStreams);        Q = q_0    else: # generate random orthonormal matrix N x r         Q = eye(numStreams) # Max size of Q        q_0, r_0 = qr(rand(numStreams,r))           Q[:,:r] = q_0                    # S_0    small_value = 0.0001    S = eye(numStreams) * small_value # Avoids Singularity        # v-1    v = zeros((numStreams,1))             # NOTE algorithm's state (constant memory), S, Q and v are kept at max size        # Use iterable for data     # Now a generator to calculate z_tl    iter_data = lag_inputs(data, L)                 # Main Loop #    #############    for t in range(1, timeSteps + 1):            #alias to matrices for current r        Qt  = Q[:, :r]        vt  = v[:r, :]        St  = S[:r, :r]            zt = iter_data.next()                  # Convert to a column Vector         # Already taken care of in this version        # zt = zt.reshape(zt.shape[0],1)             # Check S remains non-singular        for idx in range(r):            if S[idx, idx] < small_value:                S[idx,idx] = small_value                '''Begin main algorithm'''                ht = dot(Qt.T , zt)                 Z = dot(zt.T,  zt) - dot(ht.T , ht)        if Z > 0 :                        # Refined version, use of extra terms            u_vec = dot(St , vt)            X = (alpha * St) + (2 * alpha * dot(u_vec, vt.T)) + dot(ht , ht.T)                # Solve Ax = b using QR updates - not strictly needed             A = X.T            B = sqrt(Z) * ht            b_vec = np.linalg.solve(A,B) # Note: changed to solve                   beta  = 4 * (dot(b_vec.T , b_vec) + 1)                    phi_sq = 0.5 + (1.0 / sqrt(beta))                    phi = sqrt(phi_sq)                gamma = (1.0 - 2 * phi_sq) / (2 * phi)                        delta = phi / sqrt(Z)                        vt = gamma * b_vec                         St = X - ((1 /delta) * dot(vt , ht.T))                        w = (delta * ht) - (vt)                         ee = delta * zt - dot(Qt , w)                         Qt = Qt - 2 * dot(ee , vt.T)                     else: # if Z is not > 0            # Continue decay of St             St = alpha * St                #restore data structures        Q[:,:r] = Qt        v[:r,:] = vt        S[:r, :r] = St                ''' FOR EVALUATION '''        # Deviations from true dominant subspace         if evalMetrics == 'T' :            if t == 1 :                res['subspace_error'] = zeros((timeSteps,1))                res['orthog_error'] = zeros((timeSteps,1))                                res['angle_error'] = zeros((timeSteps,1))                Cov_mat = zeros([numStreams,numStreams])                            # Calculate Covarentce Matrix of data up to time t               Cov_mat = alpha * Cov_mat +  dot(zt,  zt.T)            # Get eigenvalues and eigenvectors                         W , V = eig(Cov_mat)            # Use this to sort eigenVectors in according to deccending eigenvalue            eig_idx = W.argsort() # Get sort index            eig_idx = eig_idx[::-1] # Reverse order (default is accending)            # v_r = highest r eigen vectors (accoring to thier eigenvalue if sorted).            V_r = V[:, eig_idx[:r]]                      # Calculate subspace error                    C = dot(V_r , V_r.T) - dot(Qt , Qt.T)              res['subspace_error'][t-1,0] = 10 * log10(trace(dot(C.T , C))) #frobenius norm in dB                    # Calculate angle between projection matrixes            D = dot(dot(dot(V_r.T, Qt), Qt.T), V_r)             eigVal, eigVec = eig(D)            angle = arccos(sqrt(max(eigVal)))                    res['angle_error'][t-1,0] = angle                        # Calculate deviation from orthonormality            F = dot(Qt.T , Qt) - eye(r)            res['orthog_error'][t-1,0] = 10 * log10(trace(dot(F.T , F))) #frobenius norm in dB                '''Store Values'''         # Record reconstrunted z        z_hat = dot(Qt , ht)        res['recon'][t-1,:] = z_hat.T[0,:]                # Record hidden variables        res['hidden'][t-1, :r] = ht.T[0,:]                # Record RSRE        if t == 1:            top = 0.0            bot = 0.0                    top = top + (norm(zt - z_hat) ** 2 )        bot = bot + (norm(zt) ** 2)        res['RSRE'][t-1, 0] = top / bot                # Record r        res['r_hist'][t-1, 0] = r                '''Rank Estimation'''         # Calculate energies         sumXSq = alpha * sumXSq + np.sum(zt ** 2) # Energy of Data        sumYSq = alpha * sumYSq + np.sum(ht ** 2) # Energy of hidden Variables                        res['E_t'][t-1,0] = sumXSq         res['E_dash_t'][t-1,0] = sumYSq                res['e_ratio'][t-1, 0] = sumYSq / sumXSq             if static_r == 0: # optional parameter to keep r unchanged            # Adjust Q_t ans St for change in rr            if sumYSq < (e_low * sumXSq) and lastChangeAt < (t - holdOffTime) and r < r_upper_bound and t > ignoreUp2:                                """Note indexing with r works like r + 1 as index is from 0 in python"""                # Extend Q by z_bar                h_dash = dot(Q[:, :r].T,  zt)                z_bar = zt - dot(Q[:, :r] , h_dash)                z_bar = z_bar / norm(z_bar)                Q[:numStreams, r] = z_bar.T[0,:]                                s_end  = sum(z_bar ** 2)                                # Set next row and column to zero                S[r, :] = 0.0                S[:, r] = 0.0                S[r, r] = s_end # change last element                                # new r, increment                r = r + 1         #       print "Increasing r to ", r," at time ", t, " (ratio energy", 100*sumYSq/sumXSq, ")\n"                                # Record time step of anomaly                            res['anomalies'].append(t-1)                       # Reset lastChange                             lastChangeAt = t                            elif sumYSq > e_high*sumXSq and lastChangeAt < t - holdOffTime and r > 1 and t > ignoreUp2:                    # Reset lastChange                lastChangeAt = t                # new r, decrement                r = r - 1        #        print "Decreasing r to ", r," at time ", t, " (ratio energy", 100*sumYSq/sumXSq, ")\n"                                            # No need to change S and Q as r index is decreased                                 return res def lag_inputs(data, L):    """Generator function to construct an input vector ztl that is the lagged zt     up to time l.        z_tl = [zt, zt-t, zt-2,..., zt-l]        Takes input data as a matrix.     """    N = data.shape[1]    total_timesteps = data.shape[0]        z_tl = np.zeros((L*N,1))        for i in range(total_timesteps):        #shift values         z_tl[N:] = z_tl[:-N]        # add new one to start of vector         z_tl[:N] = np.atleast_2d(data[i,:]).T                yield z_tl    if __name__ == '__main__' :         first = 1        if first:        # data = genCosSignals(0, -3.0)        # data = genCosSignals_no_rand(timesteps = 10000, N = 32)                  # data = array([[0,0,0], [1,2,2], [1,3,4], [3,6,6], [5,6,10], [6,8,11]])                   #sig_PN, ant_PN, time_PN = load_n_store('SYN', 'PN')        #data = sig_PN                AbileneMat = sio.loadmat('/Users/chris/DataSets/Abilene/Abilene.mat')        data = AbileneMat['P']                e_high = 0.98    e_low = 0.95    alpha = 0.96    holdOFF = 0    L = 5    '''My Latest version'''     res_new = FRAHST_V3_4(data, L = L, alpha=alpha, e_low=e_low, e_high=e_high,                           holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'F')         res_new['Alg'] = 'My Latest Implimentation of FRAUST '    pltSummary2(res_new, data, (e_high, e_low))            '''My previous version'''     res_old1 = FRAHST_V3_3(data, alpha=alpha, e_low=e_low, e_high=e_high,                           holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'F')     res_old1['Alg'] = 'My Previous Implimentation of FRAUST '    pltSummary2(res_old1, data, (e_high, e_low))        '''My older version'''     res_old2 = FRAHST_V3_1(data, alpha=alpha, e_low=e_low, e_high=e_high,                           holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'F')     res_old2['Alg'] = 'My Older Implimentation of FRAUST '    pltSummary2(res_old2, data, (e_high, e_low))        '''Pedros Version'''    res_ped = frahst_pedro_original(data, r=1, alpha=alpha, e_low=e_low, e_high=e_high,                          holdOffTime=holdOFF, evalMetrics='F')    res_ped['Alg'] = 'Pedros Original Implimentation of FRAUST'    pltSummary2(res_ped, data, (e_high, e_low))    first = 0