# -*- coding: utf-8 -*-"""Created on Sat Mar 05 23:19:11 2011THIS IS THE VERSION TO RUN ON MAC, NOT WINDOWS@author: musselle"""from numpy import eye, zeros, dot, sqrt, log10, trace, arccos, nan, arange, onesimport numpy as npimport scipy as spimport numpy.random as nprfrom numpy.linalg import qr, eig, norm, solvefrom matplotlib.pyplot import plot, figure, title, step, ylimfrom artSigs import genCosSignals_no_rand , genCosSignalsimport scipy.io as siofrom utils import analysis, QRsolveA, pltSummary2from PedrosFrahst import frahst_pedro_originalfrom Frahst_v3_1 import FRAHST_V3_1from Frahst_v3_3 import FRAHST_V3_3from Frahst_v3_4 import FRAHST_V3_4from Frahst_v4_0 import FRAHST_V4_0from load_syn_ping_data import load_n_storefrom QR_eig_solve import QRsolve_eigVfrom create_Abilene_links_data import create_abilene_links_datafrom MAfunctions import MA_over_windowdef FRAHST_V6_1(data, r=1, alpha=0.96, EW_alpha = 0.1,  e_low = 0.96, e_high = 0.98, fix_init_Q = 0, holdOffTime=0,                 evalMetrics = 'F', static_r = 0, r_upper_bound = None, L = 5, ignoreUp2 = 0,                data_norm_window = 50):    """        Fast Rank Adaptive Householder Subspace Tracking Algorithm (FRAHST)          Version 6.1 - basicly 6.0 but without the junk func + the actual new eigen(enegy)tracking                 - Turns out E_dash_t ~ S_trace or sum(eig_val)                            E_t ~ EW_var2(zt) discounted by alpha a la covarience matrix                    - no need to calculate incremental mean and var anymore                 - Thresholding mechanism now uses two thresholds.                     - if below the lowest -- > increment r                     - if abouve the higher --> test if (E_dast_t - eig_i ) / E_t is above e_high,                        if so remove dimentions.                      - difference between e_low and e_high acts as a 'safety' buffer, as removing an eig can                       result in too much variance being subtracted because eigs are only smoothed estimates                       of the true values. Takes time for est_eit to reach true eigs.                    - NEXT (maybe) Normalisation of data optional as a preprocessing of data.                    Version 6.0 - Aim: Different rank adjusting mechanism                      compares sum of r eigenvalues to variance of entire data.                - Performes incremental calculation of data mean and variance. (no longer in later version )    Version 5.0 - No changes of 5.0 incorperated in this version             Version 4.0 - Now also approximates eigenvalues for the approximated tracked basis for the eignevectors                          - Approach uses an orthogonal iteration arround X.T                 - Note, only a good approximation if alpha ~< 1. Used as its the fastest method                 as X.T b --> b must be solved anyway.                 - New entries in res                    ['eig_val'] - estimated eigenvalues                    ['true_eig_val'] - explicitly calculated eigenvalues (only if evalMetrics = T)             VErsion 3.4 - input data z is time lagged series up to length l.                 - Algorithm is essentially same as 3.3, just adds pre processing to data vector                - input Vector z_t is now of length (N times L) where L is window length                - Use L = 1 for same results as 3.3                 - Q is increased accordingly                     Version 3.3 - Add decay of S and in the event of vanishing inputs                 - Make sure rank of S does not drop (and work out what that means!) - stops S going singular            Version 3.2 -  Added ability to fix r to a static value., and also give it an upper bound.                   If undefined, defaults to num of data streams.             Version 3.1 - Combines good bits of Pedros version, with my correction of the bugs        Changed how the algorithm deals with sci. only difference, but somehow has a bigish     effect on the output.        """           # Initialise variables and data structures     #########################################    # Derived Variables     # Length of z or numStreams is now N x L     numStreams = data.shape[1] * L    timeSteps = data.shape[0]        if r_upper_bound == None :        r_upper_bound = numStreams        #for energy test    lastChangeAt = 1    sumYSq = 0.    sumXSq = 0.        # Data Stores    res = {'hidden' :  zeros((timeSteps, numStreams)) * nan,  # Array for hidden Variables           'E_t' : zeros([timeSteps, 1]),                     # total energy of data            'E_dash_t' : zeros([timeSteps, 1]),                # hidden var energy           'e_ratio' : zeros([timeSteps, 1]),              # Energy ratio            'RSRE' : zeros([timeSteps, 1]),           # Relative squared Reconstruction error            'recon' : zeros([timeSteps, numStreams]),  # reconstructed data           'r_hist' : zeros([timeSteps, 1]),         # history of r values            'eig_val': zeros((timeSteps, numStreams)) * nan,  # Estimated Eigenvalues            'zt_mean' : zeros((timeSteps, numStreams)), # history of data mean            'zt_var' : zeros((timeSteps, numStreams)), # history of data var             'zt_var2' : zeros((timeSteps, numStreams)), # history of data var             'S_trace' : zeros((timeSteps, 1)),          # history of S trace           'skips'   : zeros((timeSteps, 1)),          # tracks time steps where Z < 0             'Phi' : [],                 'S' : [],                 'anomalies' : []}                  # Initialisations     # Q_0    if fix_init_Q != 0:  # fix inital Q as identity         q_0 = eye(numStreams);        Q = q_0    else: # generate random orthonormal matrix N x r         Q = eye(numStreams) # Max size of Q        Q_0, R_0 = qr(rand(numStreams,r))           Q[:,:r] = Q_0                  # S_0    small_value = 0.0001    S = eye(numStreams) * small_value # Avoids Singularity        # v-1    v = zeros((numStreams,1))     # U(t-1) for eigenvalue estimation    U = eye(numStreams)    # zt mean and var    zt_mean = zeros((numStreams,1))    zt_var = zeros((numStreams,1))    zt_var2 = zeros((numStreams,1))        # NOTE algorithm's state (constant memory), S, Q and v and U are kept at max size        # Use iterable for data     # Now a generator to calculate z_tl    iter_data = lag_inputs(data, L)                 # Main Loop #    #############    for t in range(1, timeSteps + 1):            #alias to matrices for current r        Qt  = Q[:, :r]        vt  = v[:r, :]        St  = S[:r, :r]        Ut  = U[:r, :r]            zt = iter_data.next()                  '''Data Preprocessing'''        # Update zt mean and var        zt_var, zt_mean = EW_mean_var(zt, EW_alpha, zt_var, zt_mean)        zt_var2 = alpha_var(zt, alpha, zt_var2)                # Convert to a column Vector         # Already taken care of in this version        # zt = zt.reshape(zt.shape[0],1)             # Check S remains non-singular        for idx in range(r):            if S[idx, idx] < small_value:                S[idx,idx] = small_value                '''Begin main algorithm'''                ht = dot(Qt.T , zt)                 Z = dot(zt.T,  zt) - dot(ht.T , ht)        if Z > 0 :                        # Refined version, use of extra terms            u_vec = dot(St , vt)            X = (alpha * St) + (2 * alpha * dot(u_vec, vt.T)) + dot(ht , ht.T)                # Estimate eigenValues + Solve Ax = b using QR decomposition             b_vec, e_values, Ut = QRsolve_eigV(X.T, Z, ht, Ut)                        beta  = 4 * (dot(b_vec.T , b_vec) + 1)                    phi_sq = 0.5 + (1.0 / sqrt(beta))                    phi = sqrt(phi_sq)                gamma = (1.0 - 2 * phi_sq) / (2 * phi)                        delta = phi / sqrt(Z)                        vt = gamma * b_vec                         St = X - ((1 /delta) * dot(vt , ht.T))                        w = (delta * ht) - (vt)                         ee = delta * zt - dot(Qt , w)                         Qt = Qt - 2 * dot(ee , vt.T)                     else: # if Z is not > 0            if norm(zt) > 0 and norm(ht) > 0 : #Â May be due to zt <= ht                 res['skips'][t-1] = 2 # record Skips            else: # or may be due to zt and ht = 0                St = alpha * St # Continue decay of St                 res['skips'][t-1] = 1 # record Skips                #restore data structures        Q[:,:r] = Qt        v[:r,:] = vt        S[:r, :r] = St        U[:r,:r] = Ut                ''' EVALUATION '''        # Deviations from true dominant subspace         if evalMetrics == 'T' :            if t == 1 :                res['subspace_error'] = zeros((timeSteps,1))                res['orthog_error'] = zeros((timeSteps,1))                                res['angle_error'] = zeros((timeSteps,1))                res['true_eig_val'] = ones((timeSteps, numStreams)) * np.NAN                                Cov_mat = zeros([numStreams,numStreams])                            # Calculate Covarentce Matrix of data up to time t               Cov_mat = alpha * Cov_mat +  dot(zt,  zt.T)            #            res['Phi'].append(Cov_mat)            #            # Get eigenvalues and eigenvectors                         W , V = eig(Cov_mat)            # Use this to sort eigenVectors in according to deccending eigenvalue            eig_idx = W.argsort() # Get sort index            eig_idx = eig_idx[::-1] # Reverse order (default is accending)            # v_r = highest r eigen vectors (accoring to thier eigenvalue if sorted).            V_r = V[:, eig_idx[:r]]                      # Calculate subspace error                    C = dot(V_r , V_r.T) - dot(Qt , Qt.T)              res['subspace_error'][t-1,0] = 10 * log10(trace(dot(C.T , C))) #frobenius norm in dB                    # Store True r Dominant Eigenvalues            res['true_eig_val'][t-1,:r] = W[eig_idx[:r]]                        # Calculate angle between projection matrixes            #D = dot(dot(dot(V_r.T, Qt), Qt.T), V_r)             #eigVal, eigVec = eig(D)            #angle = arccos(sqrt(max(eigVal)))                    #res['angle_error'][t-1,0] = angle                        # Calculate deviation from orthonormality            F = dot(Qt.T , Qt) - eye(r)            res['orthog_error'][t-1,0] = 10 * log10(trace(dot(F.T , F))) #frobenius norm in dB                '''Store Values'''         # Record data mean and Var        res['zt_mean'][t-1,:] = zt_mean.T[0,:]        res['zt_var'][t-1,:] = zt_var.T[0,:]        res['zt_var2'][t-1,:] = zt_var2.T[0,:]                # REcord S         res['S'].append(St)                # Record S trace        res['S_trace'][t-1] = np.trace(St)                # Store eigen values        if 'e_values' not in locals():            e_values = zt_var2        else:            res['eig_val'][t-1,:r] = e_values[:r]                # Record reconstrunted z        z_hat = dot(Qt , ht)        res['recon'][t-1,:] = z_hat.T[0,:]        # Record hidden variables        res['hidden'][t-1, :r] = ht.T[0,:]                # Record RSRE        if t == 1:            top = 0.0            bot = 0.0                    top = top + (norm(zt - z_hat) ** 2 )        bot = bot + (norm(zt) ** 2)        res['RSRE'][t-1, 0] = top / bot                # Record r        res['r_hist'][t-1, 0] = r                '''Rank Estimation'''         # Calculate energies         sumXSq = alpha * sumXSq + np.sum(zt ** 2) # Energy of Data        sumYSq = alpha * sumYSq + np.sum(ht ** 2) # Energy of hidden Variables                        res['E_t'][t-1,0] = sumXSq         res['E_dash_t'][t-1,0] = sumYSq                res['e_ratio'][t-1, 0] = sumYSq / sumXSq             if static_r == 0: # optional parameter to keep r unchanged            # Adjust Q_t, St and Ut for change in r            if sumYSq < (e_low * sumXSq) and lastChangeAt < (t - holdOffTime) and r < r_upper_bound and t > ignoreUp2:                                """Note indexing with r works like r + 1 as index is from 0 in python"""                # Extend Q by z_bar                h_dash = dot(Q[:, :r].T,  zt)                z_bar = zt - dot(Q[:, :r] , h_dash)                z_bar_norm = norm(z_bar)                z_bar = z_bar / z_bar_norm                Q[:numStreams, r] = z_bar.T[0,:]                                s_end  = z_bar_norm ** 2                                # Set next row and column to zero                S[r, :] = 0.0                S[:, r] = 0.0                S[r, r] = s_end # change last element                                # Update Ut_1                # Set next row and column to zero                U[r, :] = 0.0                U[:, r] = 0.0                U[r, r] = 1.0 # change last element                                # Update eigenvalue                 e_values = sp.r_[e_values, z_bar_norm ** 2]                 # This is the bit where the estimate is off? dont really have anything better                                 # new r, increment                r = r + 1                                # Record time step of anomaly                            res['anomalies'].append(t-1)                       # Reset lastChange                             lastChangeAt = t                            elif sumYSq > (e_high * sumXSq) and lastChangeAt < t - holdOffTime and r > 1 and t > ignoreUp2:                                keeper = ones(r, dtype = bool)                # Sorted in accending order                sorted_eigs = e_values[e_values.argsort()]                acounted_var = sumYSq                for idx in range(r):                                        if ((acounted_var - sorted_eigs[idx]) / sumXSq) > e_high:                        keeper[idx] = 0                        acounted_var = acounted_var - sorted_eigs[idx]                                # use keeper as a logical selector for S and Q and U                 if not keeper.all():                                        # Delete rows/cols in Q, S, and U.                     newQ = Q[:r,:r].copy()                    newQ = newQ[keeper,:][:,keeper] # rows/cols eliminated                                            Q[:newQ.shape[0], :newQ.shape[1]] = newQ                                        newS = S[:r,:r].copy()                    newS = newS[keeper,:][:,keeper] # rows/cols eliminated                                            S[:newS.shape[0], :newS.shape[1]] = newS                                        newU = U[:r,:r].copy()                    newU = newU[keeper,:][:,keeper] # rows/cols eliminated                                            U[:newU.shape[0], :newU.shape[1]] = newU                                        r = keeper.sum()                    if r == 0 :                        r = 1                                # Reset lastChange                    lastChangeAt = t                return res def lag_inputs(data, L):    """Generator function to construct an input vector ztl that is the lagged zt     up to time l.        z_tl = [zt, zt-t, zt-2,..., zt-l]        Takes input data as a matrix.     """    N = data.shape[1]    total_timesteps = data.shape[0]        z_tl = np.zeros((L*N,1))        for i in range(total_timesteps):        #shift values         z_tl[N:] = z_tl[:-N]        # add new one to start of vector         z_tl[:N] = np.atleast_2d(data[i,:]).T                yield z_tldef alpha_var(x, alpha, var):    """ Simple exponential forgetting of Variance """    var = alpha * var + ( np.power(x,2))        return vardef EW_mean_var(x, alpha, var, mean):    """ Work out the exponentially weighted mean and variance of the data """    if alpha > 1 :        alpha = 2.0 / (alpha + 1)        diff = x - mean     incr = alpha * diff    mean = mean + incr    var = (1 - alpha) * (var + diff * incr)    return var, mean     def simple_sins(p1,p11, p2,p22, noise_scale, N = 500):        t = arange(N)                    z1 = np.sin(2 * np.pi * t / p1) + npr.randn(t.shape[0]) * noise_scale    z2 = np.sin(2 * np.pi * t / p2) + npr.randn(t.shape[0]) * noise_scale            z11 = np.sin(2 * np.pi * t / p11) + npr.randn(t.shape[0]) * noise_scale    z22 = np.sin(2 * np.pi * t / p22) + npr.randn(t.shape[0]) * noise_scale            data = sp.r_['1,2,0', sp.r_[z1, z11], sp.r_[z2, z22]]    return data def simple_sins_3z(p1,p11, p2,p22, p3, p33, noise_scale, N = 500):        t = arange(N)                    z1 = np.sin(2 * np.pi * t / p1) + npr.randn(t.shape[0]) * noise_scale    z2 = np.sin(2 * np.pi * t / p2) + npr.randn(t.shape[0]) * noise_scale    z3 = np.sin(2 * np.pi * t / p3) + npr.randn(t.shape[0]) * noise_scale            z11 = np.sin(2 * np.pi * t / p11) + npr.randn(t.shape[0]) * noise_scale    z22 = np.sin(2 * np.pi * t / p22) + npr.randn(t.shape[0]) * noise_scale    z33 = np.sin(2 * np.pi * t / p33) + npr.randn(t.shape[0]) * noise_scale            data = sp.r_['1,2,0', sp.r_[z1, z11], sp.r_[z2, z22], sp.r_[z3, z33]]    return data if __name__ == '__main__' :         first = 1        if first:        # data = genCosSignals(0, -3.0)                # data, G = create_abilene_links_data()                #execfile('/Users/chris/Dropbox/Work/MacSpyder/Utils/gen_Anomalous_peakORshift_data.py')        #data = A                #data = simple_sins(10,10,10,25, 0.1)                data = simple_sins_3z(10,10,13,13, 10, 27, 0.0)                # data = genCosSignals_no_rand(timesteps = 10000, N = 3)                  # data = array([[0,0,0], [1,2,2], [1,3,4], [3,6,6], [5,6,10], [6,8,11]])                   #sig_PN, ant_PN, time_PN = load_n_store('SYN', 'PN')        #data = sig_PN                #AbileneMat = sio.loadmat('/Users/chris/DataSets/Abilene/Abilene.mat')        #data = AbileneMat['P']                # Mean adjust data        #data_mean = MA_over_window(data,50)        #data = data - data_mean         # Fix Nans         whereAreNaNs = np.isnan(data)        data[whereAreNaNs] = 0        e_high = 0.90    e_low = 0.85    alpha = 0.96    EW_alpha = 0.1        ignoreUp2 = 50        holdOFF = 0    L = 1        # Flags    v6_1 = 1    v6_0 = 0    v4_0 = 0    v3_4 = 0    v3_3 = 0    v3_1 = 0    pedro = 0        if v6_1:        '''My Latest version'''         res_v6_1 = FRAHST_V6_1(data, L = L, alpha = alpha, EW_alpha = EW_alpha, e_low=e_low,                                 e_high = e_high, holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'T',                                 ignoreUp2 = ignoreUp2, static_r = 0, r_upper_bound = None)                 res_v6_1['Alg'] = 'My Implimentation of FRAUST Version 6.0 '        pltSummary2(res_v6_1, data, (e_high, e_low))        ylim(e_low - 0.05 , 1.02)            if v6_0:        '''My Latest version'''         res_v6_0 = FRAHST_V6_0(data, L = L, alpha = alpha, EW_alpha = EW_alpha, e_low=e_low, e_high=e_high,                                 holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'T',                                 ignoreUp2 = ignoreUp2, static_r = 0, r_upper_bound = None)                 res_v6_0['Alg'] = 'My Implimentation of FRAUST Version 6.0 '        pltSummary2(res_v6_0, data, (e_high, e_low))    if v4_0:        '''My Latest version'''         res_v4_0 = FRAHST_V4_0(data, L = L, alpha=alpha, e_low=e_low, e_high=e_high,                                 holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'T',                                 ignoreUp2 = ignoreUp2, static_r = 0, r_upper_bound = None)                 res_v4_0['Alg'] = 'My Implimentation of FRAUST Version 4.0 '        pltSummary2(res_v4_0, data, (e_high, e_low))        if v3_4:        '''My Latest version'''         res_new = FRAHST_V3_4(data, L = L, alpha=alpha, e_low=e_low, e_high=e_high,                               holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'F',                               ignoreUp2 = ignoreUp2)                 res_new['Alg'] = 'My other latest Implimentation of FRAUST '        pltSummary2(res_new, data, (e_high, e_low))        if v3_3:        '''My previous version'''         res_old1 = FRAHST_V3_3(data, alpha=alpha, e_low=e_low, e_high=e_high,                               holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'F',                               ignoreUp2 = ignoreUp2)             res_old1['Alg'] = 'My Previous Implimentation of FRAUST '        pltSummary2(res_old1, data, (e_high, e_low))        if v3_1:        '''My older version'''         res_old2 = FRAHST_V3_1(data, alpha=alpha, e_low=e_low, e_high=e_high,                               holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'F')             res_old2['Alg'] = 'My Older Implimentation of FRAUST '        pltSummary2(res_old2, data, (e_high, e_low))        if pedro:            '''Pedros Version'''        res_ped = frahst_pedro_original(data, r=1, alpha=alpha, e_low=e_low, e_high=e_high,                              holdOffTime=holdOFF, evalMetrics='F')            res_ped['Alg'] = 'Pedros Original Implimentation of FRAUST'        pltSummary2(res_ped, data, (e_high, e_low))    first = 0