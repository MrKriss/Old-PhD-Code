# -*- coding: utf-8 -*-"""Created on Sat Mar 05 23:19:11 2011THIS IS THE VERSION TO RUN ON MAC, NOT WINDOWS@author: musselle"""from numpy import eye, zeros, dot, sqrt, log10, trace, arccos, nan, arange, onesimport numpy as npimport scipy as spfrom numpy.random import randfrom numpy.linalg import qr, eig, norm, solvefrom matplotlib.pyplot import plot, figure, title, stepfrom artSigs import genCosSignals_no_rand , genCosSignalsimport scipy.io as siofrom utils import analysis, QRsolveA, pltSummary2from PedrosFrahst import frahst_pedro_originalfrom Frahst_v3_1 import FRAHST_V3_1from Frahst_v3_3 import FRAHST_V3_3from Frahst_v3_4 import FRAHST_V3_4from Frahst_v4_0 import FRAHST_V4_0from load_syn_ping_data import load_n_storefrom QR_eig_solve import QRsolve_eigVdef FRAHST_V6_0(data, r=1, alpha=0.96, EW_alpha = 0.1,  e_low = 0.96, e_high = 0.98, fix_init_Q = 0, holdOffTime=0,                 evalMetrics = 'F', static_r = 0, r_upper_bound = None, L = 5, ignoreUp2 = 0,                data_norm_window = 50):    """        Fast Rank Adaptive Householder Subspace Tracking Algorithm (FRAHST)          Version 6.0 - Different rank adjusting mechanism                      compares sum of r eigenvalues to variance of entire data.                - Performes incremental calculation of data mean and variance.                     Both are exponentially weighted with same alpha as main alpha value.                                        TODO: test on simple sinosoid data. Add it as data option in if-main methods.                                - NEXT Normalisation of data optional as a preprocessing of data.            Version 5.0 - No changes of 5.0 incorperated in this version             Version 4.0 - Now also approximates eigenvalues for the approximated tracked basis for the eignevectors                          - Approach uses an orthogonal iteration arround X.T                 - Note, only a good approximation if alpha ~< 1. Used as its the fastest method                 as X.T b --> b must be solved anyway.                 - New entries in res                    ['eig_val'] - estimated eigenvalues                    ['true_eig_val'] - explicitly calculated eigenvalues (only if evalMetrics = T)             VErsion 3.4 - input data z is time lagged series up to length l.                 - Algorithm is essentially same as 3.3, just adds pre processing to data vector                - input Vector z_t is now of length (N times L) where L is window length                - Use L = 1 for same results as 3.3                 - Q is increased accordingly                     Version 3.3 - Add decay of S and in the event of vanishing inputs                 - Make sure rank of S does not drop (and work out what that means!) - stops S going singular            Version 3.2 -  Added ability to fix r to a static value., and also give it an upper bound.                   If undefined, defaults to num of data streams.             Version 3.1 - Combines good bits of Pedros version, with my correction of the bugs        Changed how the algorithm deals with sci. only difference, but somehow has a bigish     effect on the output.        """           # Initialise variables and data structures     #########################################    # Derived Variables     # Length of z or numStreams is now N x L     numStreams = data.shape[1] * L    timeSteps = data.shape[0]        if r_upper_bound == None :        r_upper_bound = numStreams        #for energy test    lastChangeAt = 1    sumYSq = 0.    sumXSq = 0.        # Data Stores    res = {'hidden' :  zeros((timeSteps, numStreams)) * nan,  # Array for hidden Variables           'E_t' : zeros([timeSteps, 1]),                     # total energy of data            'E_dash_t' : zeros([timeSteps, 1]),                # hidden var energy           'e_ratio' : zeros([timeSteps, 1]),              # Energy ratio            'RSRE' : zeros([timeSteps, 1]),           # Relative squared Reconstruction error            'recon' : zeros([timeSteps, numStreams]),  # reconstructed data           'r_hist' : zeros([timeSteps, 1]),         # history of r values            'eig_val': zeros((timeSteps, numStreams)) * nan,  # Estimated Eigenvalues            'zt_mean' : zeros((timeSteps, numStreams)), # history of data mean            'zt_var' : zeros((timeSteps, numStreams)), # history of data var             'zt_var2' : zeros((timeSteps, numStreams)), # history of data var             'S_trace' : zeros((timeSteps, 1)),          # history of S trace           'skips'   : zeros((timeSteps, 1)),          # tracks time steps where Z < 0             'anomalies' : []}                  # Initialisations     # Q_0    if fix_init_Q != 0:  # fix inital Q as identity         q_0 = eye(numStreams);        Q = q_0    else: # generate random orthonormal matrix N x r         Q = eye(numStreams) # Max size of Q        Q_0, R_0 = qr(rand(numStreams,r))           Q[:,:r] = Q_0                  # S_0    small_value = 0.0001    S = eye(numStreams) * small_value # Avoids Singularity        # v-1    v = zeros((numStreams,1))     # U(t-1) for eigenvalue estimation    U = eye(numStreams)    # zt mean and var    zt_mean = zeros((numStreams,1))    zt_var = zeros((numStreams,1))    zt_var2 = zeros((numStreams,1))        # NOTE algorithm's state (constant memory), S, Q and v and U are kept at max size        # Use iterable for data     # Now a generator to calculate z_tl    iter_data = lag_inputs(data, L)                 # Main Loop #    #############    for t in range(1, timeSteps + 1):            #alias to matrices for current r        Qt  = Q[:, :r]        vt  = v[:r, :]        St  = S[:r, :r]        Ut  = U[:r, :r]            zt = iter_data.next()                  '''Data Preprocessing'''        # Update zt mean and var        zt_var, zt_mean = EW_mean_var(zt, EW_alpha, zt_var, zt_mean)        zt_var2 = alpha_var(zt, alpha, zt_var2)                # Convert to a column Vector         # Already taken care of in this version        # zt = zt.reshape(zt.shape[0],1)             # Check S remains non-singular        for idx in range(r):            if S[idx, idx] < small_value:                S[idx,idx] = small_value                '''Begin main algorithm'''                ht = dot(Qt.T , zt)                 Z = dot(zt.T,  zt) - dot(ht.T , ht)        if Z > 0 :                        # Refined version, use of extra terms            u_vec = dot(St , vt)            X = (alpha * St) + (2 * alpha * dot(u_vec, vt.T)) + dot(ht , ht.T)                # Estimate eigenValues + Solve Ax = b using QR decomposition             b_vec, e_values, Ut = QRsolve_eigV(X.T, Z, ht, Ut)                        # Temp, store e_values            res['eig_val'][t-1,:r] = e_values                        beta  = 4 * (dot(b_vec.T , b_vec) + 1)                    phi_sq = 0.5 + (1.0 / sqrt(beta))                    phi = sqrt(phi_sq)                gamma = (1.0 - 2 * phi_sq) / (2 * phi)                        delta = phi / sqrt(Z)                        vt = gamma * b_vec                         St = X - ((1 /delta) * dot(vt , ht.T))                        w = (delta * ht) - (vt)                         ee = delta * zt - dot(Qt , w)                         Qt = Qt - 2 * dot(ee , vt.T)                     else: # if Z is not > 0            # Continue decay of St             res['skips'][t-1] = 1            St = alpha * St                #restore data structures        Q[:,:r] = Qt        v[:r,:] = vt        S[:r, :r] = St        U[:r,:r] = Ut                ''' EVALUATION '''        # Deviations from true dominant subspace         if evalMetrics == 'T' :            if t == 1 :                res['subspace_error'] = zeros((timeSteps,1))                res['orthog_error'] = zeros((timeSteps,1))                                res['angle_error'] = zeros((timeSteps,1))                res['true_eig_val'] = ones((timeSteps, numStreams)) * np.NAN                                Cov_mat = zeros([numStreams,numStreams])                            # Calculate Covarentce Matrix of data up to time t               Cov_mat = alpha * Cov_mat +  dot(zt,  zt.T)            # Get eigenvalues and eigenvectors                         W , V = eig(Cov_mat)            # Use this to sort eigenVectors in according to deccending eigenvalue            eig_idx = W.argsort() # Get sort index            eig_idx = eig_idx[::-1] # Reverse order (default is accending)            # v_r = highest r eigen vectors (accoring to thier eigenvalue if sorted).            V_r = V[:, eig_idx[:r]]                      # Calculate subspace error                    C = dot(V_r , V_r.T) - dot(Qt , Qt.T)              res['subspace_error'][t-1,0] = 10 * log10(trace(dot(C.T , C))) #frobenius norm in dB                    # Store True r Dominant Eigenvalues            res['true_eig_val'][t-1,:r] = W[eig_idx[:r]]                        # Calculate angle between projection matrixes            D = dot(dot(dot(V_r.T, Qt), Qt.T), V_r)             eigVal, eigVec = eig(D)            angle = arccos(sqrt(max(eigVal)))                    res['angle_error'][t-1,0] = angle                        # Calculate deviation from orthonormality            F = dot(Qt.T , Qt) - eye(r)            res['orthog_error'][t-1,0] = 10 * log10(trace(dot(F.T , F))) #frobenius norm in dB                '''Store Values'''         # Record data mean and Var        res['zt_mean'][t-1,:] = zt_mean.T[0,:]                res['zt_var'][t-1,:] = zt_var.T[0,:]                res['zt_var2'][t-1,:] = zt_var2.T[0,:]                   # Record S trace        res['S_trace'][t-1] = np.trace(St)                # Record reconstrunted z        z_hat = dot(Qt , ht)        res['recon'][t-1,:] = z_hat.T[0,:]                # Record hidden variables        res['hidden'][t-1, :r] = ht.T[0,:]                # Record RSRE        if t == 1:            top = 0.0            bot = 0.0                    top = top + (norm(zt - z_hat) ** 2 )        bot = bot + (norm(zt) ** 2)        res['RSRE'][t-1, 0] = top / bot                # Record r        res['r_hist'][t-1, 0] = r                '''Rank Estimation'''         # Calculate energies         sumXSq = alpha * sumXSq + np.sum(zt ** 2) # Energy of Data        sumYSq = alpha * sumYSq + np.sum(ht ** 2) # Energy of hidden Variables                        res['E_t'][t-1,0] = sumXSq         res['E_dash_t'][t-1,0] = sumYSq                res['e_ratio'][t-1, 0] = sumYSq / sumXSq             if static_r == 0: # optional parameter to keep r unchanged            # Adjust Q_t ans St for change in rr            if sumYSq < (e_low * sumXSq) and lastChangeAt < (t - holdOffTime) and r < r_upper_bound and t > ignoreUp2:                                """Note indexing with r works like r + 1 as index is from 0 in python"""                # Extend Q by z_bar                h_dash = dot(Q[:, :r].T,  zt)                z_bar = zt - dot(Q[:, :r] , h_dash)                z_bar = z_bar / norm(z_bar)                Q[:numStreams, r] = z_bar.T[0,:]                                s_end  = sum(z_bar ** 2)                                # Set next row and column to zero                S[r, :] = 0.0                S[:, r] = 0.0                S[r, r] = s_end # change last element                                # Update Ut_1                # Set next row and column to zero                U[r, :] = 0.0                U[:, r] = 0.0                U[r, r] = 1.0 # change last element                                # new r, increment                r = r + 1         #       print "Increasing r to ", r," at time ", t, " (ratio energy", 100*sumYSq/sumXSq, ")\n"                                # Record time step of anomaly                            res['anomalies'].append(t-1)                       # Reset lastChange                             lastChangeAt = t                            elif sumYSq > e_high*sumXSq and lastChangeAt < t - holdOffTime and r > 1 and t > ignoreUp2:                                # Reset lastChange                lastChangeAt = t                # new r, decrement                r = r - 1        #        print "Decreasing r to ", r," at time ", t, " (ratio energy", 100*sumYSq/sumXSq, ")\n"                                            # No need to change S and Q and U as r index is decreased                                 return res def lag_inputs(data, L):    """Generator function to construct an input vector ztl that is the lagged zt     up to time l.        z_tl = [zt, zt-t, zt-2,..., zt-l]        Takes input data as a matrix.     """    N = data.shape[1]    total_timesteps = data.shape[0]        z_tl = np.zeros((L*N,1))        for i in range(total_timesteps):        #shift values         z_tl[N:] = z_tl[:-N]        # add new one to start of vector         z_tl[:N] = np.atleast_2d(data[i,:]).T                yield z_tl        def MA_window_gen(data, window_length):    """ Generator to yeild Incremental Average of last N data points     This is the fastest implimentation and has been tested to be equivilant to the above         Now also works with 1D array input data.    """        if data.ndim == 1:        window = np.zeros((1, window_length))        MA = np.zeros(1)        Aved_data = np.zeros_like(data)    else:        window = np.zeros((data.shape[1], window_length))        MA = np.zeros(data.shape[1])        Aved_data = np.zeros_like(data)        for i in range(data.shape[0]):        new_data_vec = data[i]        dropped_data_vec = window[:,0].copy()        window[:,:-1] = window[:,1:] # Shift Window        window[:,-1] = new_data_vec        # update average incrementally        MA = MA + ((new_data_vec - dropped_data_vec)/ float(window_length))                  yield MA    Sn = Sn + (x_i - MA[t-1]) * (x_i - MA[t])def MA_over_window(data, window_length):    """ Incremental Average of last N data points     This is the fastest implimentation and has been tested to be equivilant to the above         Now also works with 1D array input data.    """        if data.ndim == 1:        window = np.zeros((1, window_length))        Av = np.zeros(1)        Aved_data = np.zeros_like(data)    else:        window = np.zeros((data.shape[1], window_length))        Av = np.zeros(data.shape[1])        Aved_data = np.zeros_like(data)        for i in range(data.shape[0]):        new_data_vec = data[i]        dropped_data_vec = window[:,0].copy()        window[:,:-1] = window[:,1:] # Shift Window        window[:,-1] = new_data_vec        # update average incrementally        Av = Av + ((new_data_vec - dropped_data_vec)/ float(window_length))                  Aved_data[i] = Av            return Aved_datadef alpha_var(x, alpha, var):    """ Simple exponential forgetting of Variance """    var = alpha * var + ( np.power(x,2))        return vardef EW_mean_var(x, alpha, var, mean):    """ Work out the exponentially weighted mean and variance of the data """    if alpha > 1 :        alpha = 2.0 / (alpha + 1)        diff = x - mean     incr = alpha * diff    mean = mean + incr    var = (1 - alpha) * (var + diff * incr)    return var, mean     def simple_sins(p1,p11, p2,p22, N = 500):        t = arange(N)                    z1 = np.sin(2 * np.pi * t / p1)    z2 = np.sin(2 * np.pi * t / p2)            z11 = np.sin(2 * np.pi * t / p11)    z22 = np.sin(2 * np.pi * t / p22)            data = sp.r_['1,2,0', sp.r_[z1, z11], sp.r_[z2, z22]]    return data if __name__ == '__main__' :         first = 1        if first:        # data = genCosSignals(0, -3.0)                #execfile('/Users/chris/Dropbox/Work/MacSpyder/Utils/gen_Anomalous_peakORshift_data.py')        #data = A                data = simple_sins(10,10,10,25)                # data = genCosSignals_no_rand(timesteps = 10000, N = 3)                  # data = array([[0,0,0], [1,2,2], [1,3,4], [3,6,6], [5,6,10], [6,8,11]])                   #sig_PN, ant_PN, time_PN = load_n_store('SYN', 'PN')        #data = sig_PN                #AbileneMat = sio.loadmat('/Users/chris/DataSets/Abilene/Abilene.mat')        #data = AbileneMat['P']        e_high = 0.98    e_low = 0.65    alpha = 0.96    EW_alpha = 0.1        ignoreUp2 = 50        holdOFF = 0    L = 1        # Flags    v6_0 = 1    v4_0 = 0    v3_4 = 0    v3_3 = 0    v3_1 = 0    pedro = 0        if v6_0:        '''My Latest version'''         res_v6_0 = FRAHST_V6_0(data, L = L, alpha = alpha, EW_alpha = EW_alpha, e_low=e_low, e_high=e_high,                                 holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'T',                                 ignoreUp2 = ignoreUp2, static_r = 0, r_upper_bound = None)                 res_v6_0['Alg'] = 'My Implimentation of FRAUST Version 6.0 '        pltSummary2(res_v6_0, data, (e_high, e_low))    if v4_0:        '''My Latest version'''         res_v4_0 = FRAHST_V4_0(data, L = L, alpha=alpha, e_low=e_low, e_high=e_high,                                 holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'T',                                 ignoreUp2 = ignoreUp2, static_r = 0, r_upper_bound = None)                 res_v4_0['Alg'] = 'My Implimentation of FRAUST Version 4.0 '        pltSummary2(res_v4_0, data, (e_high, e_low))        if v3_4:        '''My Latest version'''         res_new = FRAHST_V3_4(data, L = L, alpha=alpha, e_low=e_low, e_high=e_high,                               holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'F',                               ignoreUp2 = ignoreUp2)                 res_new['Alg'] = 'My other latest Implimentation of FRAUST '        pltSummary2(res_new, data, (e_high, e_low))        if v3_3:        '''My previous version'''         res_old1 = FRAHST_V3_3(data, alpha=alpha, e_low=e_low, e_high=e_high,                               holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'F',                               ignoreUp2 = ignoreUp2)             res_old1['Alg'] = 'My Previous Implimentation of FRAUST '        pltSummary2(res_old1, data, (e_high, e_low))        if v3_1:        '''My older version'''         res_old2 = FRAHST_V3_1(data, alpha=alpha, e_low=e_low, e_high=e_high,                               holdOffTime=holdOFF, fix_init_Q = 1, r = 1, evalMetrics = 'F')             res_old2['Alg'] = 'My Older Implimentation of FRAUST '        pltSummary2(res_old2, data, (e_high, e_low))        if pedro:            '''Pedros Version'''        res_ped = frahst_pedro_original(data, r=1, alpha=alpha, e_low=e_low, e_high=e_high,                              holdOffTime=holdOFF, evalMetrics='F')            res_ped['Alg'] = 'Pedros Original Implimentation of FRAUST'        pltSummary2(res_ped, data, (e_high, e_low))    first = 0